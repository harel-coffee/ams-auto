#!/usr/bin/env python3


from argparse import ArgumentParser
import os
import pickle

import numpy as np
import pandas as pd
import seaborn as sns
import tqdm

import sys
sys.path.append("../")
sys.path.append(".")
from core import nlp
from core.code_to_api import compute_matches
from core.generate_search_space import get_sorted_code_matches
from core.extract_sklearn_api import (
    APICollection,
    APIClass,
    APIClassParameter,
)


def sample_initial_components(api_collection, n):
    sampled = np.random.choice(api_collection.classes, n, replace=False)
    return [elem.path for elem in sampled]


def query_randomly(api_collection, code, k):
    random_results = {}
    classes = [c.path for c in api_collection.classes]
    n = classes
    for query in code:
        # add a random score
        query_results = list(zip(classes, np.random.uniform(size=n)))
        random_results[query] = query_results
    return get_sorted_code_matches(
        random_results,
        k + 1,
        is_classification=False,
        perform_ad_hoc_filter=False,
    )


def query_embeddings(api_collection, code, k):
    matched = compute_matches(api_collection, code, strategy="embeddings")
    return get_sorted_code_matches(
        matched,
        k + 1,
        is_classification=False,
        perform_ad_hoc_filter=False,
    )


def query_bm25(api_collection, code, k):
    matched = compute_matches(api_collection, code, strategy="bm25")
    return get_sorted_code_matches(
        matched,
        k + 1,
        is_classification=False,
        perform_ad_hoc_filter=False,
    )


def get_table_for_manual_marking(
        api_collection,
        n,
        k,
        method=None,
        sampled=None,
):
    if sampled is None:
        sampled = sample_initial_components(api_collection, n)
    else:
        sampled = pd.read_csv(sampled)
        sampled = sampled.groupby("class").head(1)["class"].values
        n = len(sampled)

    if method is None:
        method = "embeddings"

    if method == "embeddings":
        query_results = query_embeddings(api_collection, sampled, k)
    elif method == "random":
        query_results = query_randomly(api_collection, sampled, k)
    elif method == "bm25":
        query_results = query_bm25(api_collection, sampled, k)
    else:
        raise ValueError("Unknown search method:" + method)

    assert len(query_results) == n, "Missing queries"
    acc = []
    for sampled_id, class_ in tqdm.tqdm(enumerate(sampled)):
        class_results = query_results[class_]
        # remove self from results
        class_results = [c for c in class_results if c != class_]
        assert len(class_results) == k, "Missing component results"
        for position, retrieved in enumerate(class_results):
            acc.append((sampled_id, class_, position, retrieved))
    return pd.DataFrame(
        acc,
        columns=["sampled_id", "class", "result_position", "result"],
    )


def get_args():
    parser = ArgumentParser(
        description=
        "Experiment to evaluate ability of embeddings to retrieve semantically related components from API",
    )
    parser.add_argument("--api", type=str, help="Pickled API collection")
    parser.add_argument(
        "--sampled",
        type=str,
        help=
        "Dataframe generated by this tool, so use classes present there rather than new sample",
    )
    parser.add_argument(
        "--n",
        type=int,
        help=
        "Number of initial classes to sample (each corresponds to a query)",
    )
    parser.add_argument(
        "--k",
        type=int,
        help="Number of results to retrieve per query",
    )
    parser.add_argument(
        "--method",
        choices=["embeddings", "bm25", "random"],
        help="Search method for component retrieval",
    )
    parser.add_argument(
        "--output",
        type=str,
        help="Output",
    )
    parser.add_argument(
        "--seed",
        type=int,
        help="RNG seed",
        default=42,
    )
    return parser.parse_args()


def main():
    args = get_args()
    np.random.seed(args.seed)
    with open(args.api, "rb") as fin:
        api_collection = pickle.load(fin)
    df = get_table_for_manual_marking(
        api_collection,
        args.n,
        args.k,
        method=args.method,
        sampled=args.sampled
    )
    if not os.path.exists(os.path.dirname(args.output)):
        os.makedirs(os.path.dirname(args.output))
    df.to_csv(args.output, index=False)


if __name__ == "__main__":
    try:
        main()
    except Exception as err:
        import pdb
        pdb.post_mortem()
